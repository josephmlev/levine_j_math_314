{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import binom\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9.23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Population mean\n",
    "\n",
    "$\\textbf{E}(X) = \\sum_S x f(x) $ \n",
    "\n",
    "if $X$ ~ $\\text{Binomial}(K, p)$\n",
    "\n",
    "it turns out $\\textbf{E}(X) = K p $ \n",
    "\n",
    "#### example\n",
    "$X$ ~ $\\text{Binomial}(K = 10, p = .5)$ we expect 5 heads. $\\textbf{E}(X) = 10 * .5 = 5$\n",
    "\n",
    "#### example\n",
    "$X$ ~ $\\text{Binomial}(K = 11, p = .5)$ we expect 5.5 heads. $\\textbf{E}(X) = 11 * .5 = 5.5$. Population means do not need to be values in the support of the RV itself.\n",
    "\n",
    "#### example\n",
    "$X$ ~ $\\text{uniform}(a, b) \\rightarrow \\textbf{E}(x) = \\frac{b + a}{2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Likelihood Method\n",
    "\n",
    "$L(\\theta | x) = \\prod_{n = 1}^{N} f(x_n | \\theta)$\n",
    "\n",
    "$\\theta$ - populations parameter(s)\n",
    "\n",
    "$L$ - liklihood function\n",
    "\n",
    "$f(x)$ - probability density function\n",
    "\n",
    "$x_n$ - the observed RV in the array \n",
    "\n",
    "$x$ - the array of observed data\n",
    "\n",
    "#### Goal: What is the most likely value of \\theta, given the observed data x\n",
    "$\\hat{\\theta}$ = argmax$[L(\\theta | x)]$ Call $\\hat\\theta$ the maximum likelihood estimator\n",
    "\n",
    "#### example\n",
    "$X_1, X_2, ... X_N $ ~ Binomial$(K, p)$\n",
    "\n",
    "$L(p | x, K) = \\prod_{n = 1}^N$  $K\\choose{  n}$ $p^{x_n}(1-p)^{K - x_n}$\n",
    "\n",
    "    0) Take natural log (makes it easier for computer)\n",
    "    1) Take derivative with respect to p and simplify\n",
    "    2) Set derivative equal to 0\n",
    "    3) solve for p\n",
    "    \n",
    "board math $\\rightarrow \\hat p = \\frac{\\sum x_n}{K N}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "music recomendation: kokoroko"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$X_1, ..., X_N$ ~ Binomial$(K, p)$\n",
    "\n",
    "$L(p|\\underline X, k)$ Given the data what is the most likley value of pop paramater p. \n",
    "\n",
    "$L(p|\\underline X, k) = \\prod_{n = 1}^ N f(X_N|p)$\n",
    "\n",
    "We want the \"maximum likliyhood estimator\", $\\hat p = \\text{argmax}_p L(p|\\underline X, k)$\n",
    "\n",
    "for simplicity take natural log. he calls it ln\n",
    "\n",
    "$ln(L(p|\\underline{X}, k))\\\\ \n",
    "= \\sum_{n = 1} ^ N ln f(x_n | p)\\\\ \n",
    "= \\sum_{n = 1} ^ N ln({k \\choose N} p^{x_n} * (1-p)^{k-x_n})\\\\ =\\sum_{n = 1} ^ N ln({k \\choose N}) + ln( p^{x_n}) + ln( (1-p)^{k-x_n}) \\\\\n",
    "= \\sum_{n = 1} ^ N ln({k \\choose N}) + x_n ln( p) + (k-x_n) ln (1-p)\\\\ \n",
    "\\propto _p \\sum_{n = 1} ^ N x_n ln( p) + *(k-x_n) ln (1-p) $\n",
    "\n",
    "Lets write this simplified log-likelihood function in python\n",
    "\n",
    "def(LL_binomial(p, X, k)):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why is it a product example:\n",
    "Bernoulli = H, T, H\n",
    "\n",
    "p of this outcome = p * (1-p) * p\n",
    "\n",
    "p came from the probability density function, so this is really $f(1) * f(0) * f(1) = f(x_1) * ... = \\prod_{n = 1} ^N f(x_n) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now take $\\frac{d}{dp}\\sum_{n = 1} ^ N x_n ln( p) + (k-x_n) ln (1-p)  \\\\ = \\sum_{n = 1} ^ N \\frac{p}{ x_n} - \\frac{k-x_n} {1-p}   $ \n",
    "\n",
    "so,\n",
    "\n",
    "$\\sum_{n = 1} ^ N \\frac{p}{ x_n} = \\sum_{n = 1} ^ N \\frac{k-x_n} {1-p}$\n",
    "\n",
    "\n",
    "$\\sum_{n = 1} ^ N x_n - p \\sum_{n = 1} ^ N x_n   = p * K * k - p \\sum_{n = 1} ^ N x_n$\n",
    "\n",
    "\n",
    "$\\sum_{n = 1} ^ N x_n    = p * K * k $\n",
    "\n",
    "This gives $\\hat p$, maximum likliyhood estimator\n",
    "\n",
    "$\\hat p  = \\frac{\\sum_{n = 1} ^ N x_n}{N * k}$\n",
    "\n",
    "This is intutitive. $\\textbf{E}(X) = k * p$ and the sample mean is $\\frac{\\sum_{n = 1} ^ N x_n}{N}$ so $\\hat p $ is the mean over k, the piece you don't want\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ll_binomial(p, X, K):\n",
    "    N = X.size\n",
    "    Sx = np.sum(X)\n",
    "    return -1 * np.log(p) * Sx - (N * K - Sx) * np.log(1 - p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 12\n",
    "X = np.random.binomial(K, 0.6, size = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      fun: array([15.27634004])\n",
       " hess_inv: <1x1 LbfgsInvHessProduct with dtype=float64>\n",
       "      jac: array([7.46069873e-06])\n",
       "  message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
       "     nfev: 12\n",
       "      nit: 4\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([0.66666673])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#minimize(function, tuple of best guess, \n",
    "#arguements, method (always use this), bounds) \n",
    "#this is in hw 10\n",
    "\n",
    "minimize(ll_binomial, (0.5), args = (X, K), \n",
    "         method = \"L-BFGS-B\", bounds = [(1e-5, 1 - 1e-5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
