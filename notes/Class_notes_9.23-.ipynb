{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9.23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Population mean\n",
    "\n",
    "$\\textbf{E}(X) = \\sum_S x f(x) $ \n",
    "\n",
    "if $X$ ~ $\\text{Binomial}(K, p)$\n",
    "\n",
    "it turns out $\\textbf{E}(X) = K p $ \n",
    "\n",
    "#### example\n",
    "$X$ ~ $\\text{Binomial}(K = 10, p = .5)$ we expect 5 heads. $\\textbf{E}(X) = 10 * .5 = 5$\n",
    "\n",
    "#### example\n",
    "$X$ ~ $\\text{Binomial}(K = 11, p = .5)$ we expect 5.5 heads. $\\textbf{E}(X) = 11 * .5 = 5.5$. Population means do not need to be values in the support of the RV itself.\n",
    "\n",
    "#### example\n",
    "$X$ ~ $\\text{uniform}(a, b) \\rightarrow \\textbf{E}(x) = \\frac{b + a}{2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Likelihood Method\n",
    "\n",
    "$L(\\theta | x) = \\prod_{n = 1}^{N} f(x_n | \\theta)$\n",
    "\n",
    "$\\theta$ - populations parameter(s)\n",
    "\n",
    "$L$ - liklihood function\n",
    "\n",
    "$f(x)$ - probability density function\n",
    "\n",
    "$x_n$ - the observed RV in the array \n",
    "\n",
    "$x$ - the array of observed data\n",
    "\n",
    "#### Goal: What is the most likely value of \\theta, given the observed data x\n",
    "$\\hat{\\theta}$ = argmax$[L(\\theta | x)]$ Call $\\hat\\theta$ the maximum likelihood estimator\n",
    "\n",
    "#### example\n",
    "$X_1, X_2, ... X_N $ ~ Binomial$(K, p)$\n",
    "\n",
    "$L(p | x, K) = \\prod_{n = 1}^N$  $K\\choose{  n}$ $p^{x_n}(1-p)^{K - x_n}$\n",
    "\n",
    "    0) Take natural log (makes it easier for computer)\n",
    "    1) Take derivative with respect to p and simplify\n",
    "    2) Set derivative equal to 0\n",
    "    3) solve for p\n",
    "    \n",
    "board math $\\rightarrow \\hat p = \\frac{\\sum x_n}{K N}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "music recomendation: kokoroko"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$X_1, ..., X_N$ ~ Binomial$(K, p)$\n",
    "\n",
    "$L(p|\\underline X, k)$ Given the data what is the most likley value of pop paramater p. \n",
    "\n",
    "$L(p|\\underline X, k) = \\prod_{n = 1}^ N f(X_N|p)$\n",
    "\n",
    "We want the \"maximum likliyhood estimator\", $\\hat p = \\text{argmax}_p L(p|\\underline X, k)$\n",
    "\n",
    "for simplicity take natural log. he calls \"ln\" \"log\"\n",
    "\n",
    "$ln(L(p|\\underline{X}, k))\\\\ \n",
    "= \\sum_{n = 1} ^ N ln f(x_n | p)\\\\ \n",
    "= \\sum_{n = 1} ^ N ln({k \\choose N} p^{x_n} * (1-p)^{k-x_n})\\\\ =\\sum_{n = 1} ^ N ln({k \\choose N}) + ln( p^{x_n}) + ln( (1-p)^{k-x_n}) \\\\\n",
    "= \\sum_{n = 1} ^ N ln({k \\choose N}) + x_n ln( p) + (k-x_n) ln (1-p)\\\\ \n",
    "\\propto _p \\sum_{n = 1} ^ N x_n ln( p) + *(k-x_n) ln (1-p) $\n",
    "\n",
    "Lets write this simplified log-likelihood function in python\n",
    "\n",
    "def(LL_binomial(p, X, k)):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why is it a product example:\n",
    "Bernoulli = H, T, H\n",
    "\n",
    "p of this outcome = p * (1-p) * p\n",
    "\n",
    "p came from the probability density function, so this is really $f(1) * f(0) * f(1) = f(x_1) * ... = \\prod_{n = 1} ^N f(x_n) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now take $\\frac{d}{dp}\\sum_{n = 1} ^ N x_n ln( p) + (k-x_n) ln (1-p)  \\\\ = \\sum_{n = 1} ^ N \\frac{p}{ x_n} - \\frac{k-x_n} {1-p}   $ \n",
    "\n",
    "so,\n",
    "\n",
    "$\\sum_{n = 1} ^ N \\frac{p}{ x_n} = \\sum_{n = 1} ^ N \\frac{k-x_n} {1-p}$\n",
    "\n",
    "\n",
    "$\\sum_{n = 1} ^ N x_n - p \\sum_{n = 1} ^ N x_n   = p * K * k - p \\sum_{n = 1} ^ N x_n$\n",
    "\n",
    "\n",
    "$\\sum_{n = 1} ^ N x_n    = p * K * k $\n",
    "\n",
    "This gives $\\hat p$, maximum likliyhood estimator\n",
    "\n",
    "$\\hat p  = \\frac{\\sum_{n = 1} ^ N x_n}{N * k}$\n",
    "\n",
    "This is intutitive. $\\textbf{E}(X) = k * p$ and the sample mean is $\\frac{\\sum_{n = 1} ^ N x_n}{N}$ so $\\hat p $ is the mean over k, the piece you don't want\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ll_binomial(p, X, K):\n",
    "    N = X.size\n",
    "    Sx = np.sum(X)\n",
    "    return -1 * np.log(p) * Sx - (N * K - Sx) * np.log(1 - p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1001\n",
    "K = 12\n",
    "X = np.random.binomial(K, 0.6, size = N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      fun: array([8062.74711211])\n",
       " hess_inv: <1x1 LbfgsInvHessProduct with dtype=float64>\n",
       "      jac: array([-9.09494702e-05])\n",
       "  message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
       "     nfev: 14\n",
       "      nit: 5\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([0.60431235])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#minimize(function, tuple of best guess, \n",
    "#arguements, method (always use this), bounds) \n",
    "#this is in hw 10\n",
    "\n",
    "minimize(ll_binomial, (0.5), args = (X, K), \n",
    "         method = \"L-BFGS-B\", bounds = [(1e-5, 1 - 1e-5)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9.26\n",
    "### Why math on a computer is hard\n",
    "\n",
    "in yesterday's example, we needed soft bounds else ln(0) is undefined and its bad!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-ee7fbf6c8e67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m101\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mll_binomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "p = np.linspace(1e-5, 1-1e-5, 101)\n",
    "p\n",
    "plt.plot(p, ll_binomial(p, X, K))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gamma Random Variable\n",
    "This is like homework 11\n",
    "\n",
    "$f(x|\\alpha, \\beta) = (\\beta^\\alpha \\Gamma(\\alpha))^{-1} x^{\\alpha - 1} e^{\\frac{-x} {\\beta}}$ for $\\alpha > 0, \\beta > 0, x > 0$\n",
    "\n",
    "$\\Gamma$ function is the generilization of factorial to non ints. if $\\alpha$ is an int,\n",
    "\n",
    "$\\Gamma(\\alpha) = (\\alpha - 1)!$\n",
    "\n",
    "but really,\n",
    "\n",
    "$\\Gamma(\\alpha) = \\int_0 ^\\infty x^{\\alpha - 1} e ^ x dx$\n",
    "\n",
    "Lets make a lileleyhood function\n",
    "$L(\\alpha, \\beta |\\underline{x}) = \\prod_{n=1}^N f(x_n|\\alpha, \\beta)$\n",
    "\n",
    "0) take log\n",
    "\n",
    "$\\sum log(f(x_n|\\alpha,\\beta))$\n",
    "\n",
    "$\\sum [-\\alpha log(\\beta) - log(\\Gamma(\\alpha)) + (\\alpha - 1) log(x_n) - \\frac{x_n}{\\beta}]$\n",
    "\n",
    "Screw this! Python does the derivitaves!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import loggamma\n",
    "def ll_gamma(theta, X):\n",
    "    alpha = theta[0]\n",
    "    beta = theta[1]\n",
    "    Sx = np.sum(X)\n",
    "    N = X.size\n",
    "    return N * alpha * np.log(beta) + N * loggamma(alpha) -\\\n",
    "    (alpha - 1 ) * np.sum(np.log(X)) + Sx / beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1001\n",
    "a = 1.24\n",
    "b = 12.43\n",
    "X = np.random.gamma(a,b,size = N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      fun: 3699.2332225827786\n",
       " hess_inv: <2x2 LbfgsInvHessProduct with dtype=float64>\n",
       "      jac: array([-9.09494702e-05, -9.09494702e-05])\n",
       "  message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
       "     nfev: 60\n",
       "      nit: 19\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([ 1.22090188, 12.27675704])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minimize(ll_gamma, (1,1), args = (X), \n",
    "         method = \"L-BFGS-B\", bounds = [(1e-5, np.inf), (1 - 1e-5, np.inf)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9.30\n",
    "### Differences between discrete and continous RV's\n",
    "\n",
    "Discrete RVs can take on at most a countably infinite set of values. $\\sum_{\\text{support}}f(x) = 1$\n",
    "\n",
    "Continuous have an uncountably infinite set of values. Now $\\int_{\\text{support}} f(x) dx = 1$\n",
    "\n",
    "$\\textbf{E}(g(x)) = \\int_\\text{support} g(x) * f(x) dx$\n",
    "\n",
    "#### ex\n",
    "$X$ ~ Exponential($\\lambda$)\n",
    "\n",
    "$f(x|\\lambda) = \\lambda e^{-\\lambda x}$\n",
    "\n",
    "Find $\\textbf{E}(X)$\n",
    "\n",
    "Just apply definition!\n",
    "\n",
    "$\\textbf{E}(g(x)) = \\int_0 ^\\infty x  \\lambda e^{-\\lambda x} dx$\n",
    "\n",
    "parts\n",
    "\n",
    "$= \\frac{1}{\\lambda}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10/7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$X$ ~ Normal($\\mu, \\sigma ^2$)\n",
    "\n",
    "$\\textbf{E}(X) = \\mu$\n",
    "\n",
    "$\\textbf{V}(X) = \\sigma^2$\n",
    "\n",
    "Normal variable\n",
    "\n",
    "    \"bell curve\"\n",
    "    unimodal (one hump)\n",
    "    symmetric about $\\mu$\n",
    "    \n",
    "Ex: let $Y = X - \\mu$\n",
    "\n",
    "$\\textbf{E}(Y) = \\textbf{E}(X - \\mu) = \\textbf{E}(X) - \\mu$ \n",
    "\n",
    "This works because expectation is linear\n",
    "\n",
    "Subtract mean off of variable shifts distrubtion about zero\n",
    "\n",
    "so\n",
    "\n",
    "$ \\mu - \\mu = 0$\n",
    "\n",
    "Ex: let $Y = \\frac{X - \\mu}{\\sigma}$\n",
    "\n",
    "$\\textbf{E}(Y) = \\frac{1}{\\sigma} \\textbf{E}(X - \\mu) = 0 $\n",
    "\n",
    "for the same reason as before\n",
    "    \n",
    "Ex: let $Y = \\frac{X - \\mu}{\\sigma}$\n",
    "\n",
    "$\\textbf{V}(Y) = \\textbf{V}(\\frac{X - \\mu}{\\sigma}) = \\frac{1}{\\sigma^2} \\textbf{V}(X - \\mu) = \\frac{1}{\\sigma^2} \\textbf{V}(X) = \\frac{1}{\\sigma^2} * \\sigma^2 = 1$\n",
    "\n",
    "SO: by letting  $Y = \\frac{X - \\mu}{\\sigma}$ we take our normally distributed random variable and center it about zero with variance 1\n",
    "\n",
    "Sample mean itself is not a constant, it is its own RV. This is because it is an opperation that depends on RVs. Expecations do return constants because they opperate on population means where as sample means depend on real data with $N$ data points.\n",
    "\n",
    "$$\\textbf{E}(\\frac{1}{N} \\sum_{n=1}^N X_n) = \\frac{1}{N} \\textbf{E}(\\sum_{n=1}^N X_n)$$\n",
    "$$= \\frac{1}{N} \\sum_{n=1}^N  \\textbf{E}(X_n)$$\n",
    "$$= \\frac{1}{N} N \\mu = \\mu$$\n",
    "\n",
    "Let $X_1, ..., X_N$~$F$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$X_1, ..., X_N$~$F$, all of which are independent\n",
    "$$\\textbf{V}(\\frac{1}{N} \\sum_{n=1}^N X_n) = \\frac{1}{N^2} \\textbf{V}(\\sum_{n=1}^N X_n)$$\n",
    "\n",
    "assuming independance,\n",
    "\n",
    "$$=\\frac{1}{N^2} \\sum_{n=1}^N  \\textbf{V}(X_n) $$\n",
    "\n",
    "$$= \\frac{\\sigma^2}{N}$$\n",
    "\n",
    "This is our uncertanty. The variance of the mean is the width of the guesses of the mean. \n",
    "\n",
    "We are quantifying how wrong our guesses are"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $\\textbf{E}(X) = \\mu$, all independant\n",
    "\n",
    "if $\\textbf{E}(X)  = \\mu & \\textbf{V}(X) = \\simga^2 < \\infty\n",
    "\n",
    "then\n",
    "\n",
    "$$\\frac{\\hat \\mu - \\mu}{\\frac{\\sigma}{\\sqrt{N}}} \\sim N(0,1) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
